{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower noise (0.71824836862138408, 7.3240173129983507e-49)\n",
      "Higher noise (0.057964292079338155, 0.31700993885324752)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "np.random.seed(0)\n",
    "size = 300\n",
    "x = np.random.normal(0, 1, size)\n",
    "print (\"Lower noise\", pearsonr(x, x + np.random.normal(0, 1, size)))\n",
    "print (\"Higher noise\", pearsonr(x, x + np.random.normal(0, 10, size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.00230804707612\n"
     ]
    }
   ],
   "source": [
    "x = np.random.uniform(-1, 1, 100000)\n",
    "print (pearsonr(x, x**2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "from minepy import MINE\n",
    "m = MINE()\n",
    "x = np.random.uniform(-1, 1, 10000)\n",
    "m.compute_score(x, x**2)\n",
    "print (m.mic())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tim.wu/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.64300000000000002, 'LSTAT'), (0.56799999999999995, 'RM'), (0.51600000000000001, 'NOX'), (0.29799999999999999, 'PTRATIO'), (0.28399999999999997, 'INDUS'), (0.26300000000000001, 'TAX'), (0.23000000000000001, 'CRIM'), (0.20999999999999999, 'ZN'), (0.16200000000000001, 'RAD'), (0.10100000000000001, 'AGE'), (0.092999999999999999, 'B'), (0.025000000000000001, 'CHAS'), (-0.043999999999999997, 'DIS')]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score, ShuffleSplit\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    " \n",
    "#Load boston housing dataset as an example\n",
    "boston = load_boston()\n",
    "X = boston[\"data\"]\n",
    "Y = boston[\"target\"]\n",
    "names = boston[\"feature_names\"]\n",
    " \n",
    "rf = RandomForestRegressor(n_estimators=20, max_depth=4)\n",
    "scores = []\n",
    "for i in range(X.shape[1]):\n",
    "     score = cross_val_score(rf, X[:, i:i+1], Y, scoring=\"r2\",\n",
    "                              cv=ShuffleSplit(len(X), 3, .3))\n",
    "     scores.append((round(np.mean(score), 3), names[i]))\n",
    "print (sorted(scores, reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear model: 0.984 * X0 + 1.995 * X1 + -0.041 * X2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    " \n",
    "np.random.seed(0)\n",
    "size = 5000\n",
    " \n",
    "#A dataset with 3 features\n",
    "X = np.random.normal(0, 1, (size, 3))\n",
    "#Y = X0 + 2*X1 + noise\n",
    "Y = X[:,0] + 2*X[:,1] + np.random.normal(0, 2, size)\n",
    "lr = LinearRegression()\n",
    "lr.fit(X, Y)\n",
    " \n",
    "#A helper method for pretty-printing linear models\n",
    "def pretty_print_linear(coefs, names = None, sort = False):\n",
    "    if names == None:\n",
    "        names = [\"X%s\" % x for x in range(len(coefs))]\n",
    "    lst = zip(coefs, names)\n",
    "    if sort:\n",
    "        lst = sorted(lst,  key = lambda x:-np.abs(x[0]))\n",
    "    return \" + \".join(\"%s * %s\" % (round(coef, 3), name)\n",
    "                                   for coef, name in lst)\n",
    " \n",
    "print (\"Linear model:\", pretty_print_linear(lr.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso model:  -3.707 * LSTAT + 2.992 * RM + -1.757 * PTRATIO + -1.081 * DIS + -0.7 * NOX + 0.631 * B + 0.54 * CHAS + -0.236 * CRIM + 0.081 * ZN + -0.0 * INDUS + -0.0 * AGE + 0.0 * RAD + -0.0 * TAX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tim.wu/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:16: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_boston\n",
    "  \n",
    "boston = load_boston()\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(boston[\"data\"])\n",
    "Y = boston[\"target\"]\n",
    "names = boston[\"feature_names\"]\n",
    "  \n",
    "lasso = Lasso(alpha=.3)\n",
    "lasso.fit(X, Y)\n",
    "  \n",
    "print (\"Lasso model: \", pretty_print_linear(lasso.coef_, names, sort = True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed 0\n",
      "Linear model: 0.728 * X0 + 2.309 * X1 + -0.082 * X2\n",
      "Ridge model: 0.938 * X0 + 1.059 * X1 + 0.877 * X2\n",
      "\n",
      "Random seed 1\n",
      "Linear model: 1.152 * X0 + 2.366 * X1 + -0.599 * X2\n",
      "Ridge model: 0.984 * X0 + 1.068 * X1 + 0.759 * X2\n",
      "\n",
      "Random seed 2\n",
      "Linear model: 0.697 * X0 + 0.322 * X1 + 2.086 * X2\n",
      "Ridge model: 0.972 * X0 + 0.943 * X1 + 1.085 * X2\n",
      "\n",
      "Random seed 3\n",
      "Linear model: 0.287 * X0 + 1.254 * X1 + 1.491 * X2\n",
      "Ridge model: 0.919 * X0 + 1.005 * X1 + 1.033 * X2\n",
      "\n",
      "Random seed 4\n",
      "Linear model: 0.187 * X0 + 0.772 * X1 + 2.189 * X2\n",
      "Ridge model: 0.964 * X0 + 0.982 * X1 + 1.098 * X2\n",
      "\n",
      "Random seed 5\n",
      "Linear model: -1.291 * X0 + 1.591 * X1 + 2.747 * X2\n",
      "Ridge model: 0.758 * X0 + 1.011 * X1 + 1.139 * X2\n",
      "\n",
      "Random seed 6\n",
      "Linear model: 1.199 * X0 + -0.031 * X1 + 1.915 * X2\n",
      "Ridge model: 1.016 * X0 + 0.89 * X1 + 1.091 * X2\n",
      "\n",
      "Random seed 7\n",
      "Linear model: 1.474 * X0 + 1.762 * X1 + -0.151 * X2\n",
      "Ridge model: 1.018 * X0 + 1.039 * X1 + 0.901 * X2\n",
      "\n",
      "Random seed 8\n",
      "Linear model: 0.084 * X0 + 1.88 * X1 + 1.107 * X2\n",
      "Ridge model: 0.907 * X0 + 1.071 * X1 + 1.008 * X2\n",
      "\n",
      "Random seed 9\n",
      "Linear model: 0.714 * X0 + 0.776 * X1 + 1.364 * X2\n",
      "Ridge model: 0.896 * X0 + 0.903 * X1 + 0.98 * X2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "size = 100\n",
    " \n",
    "#We run the method 10 times with different random seeds\n",
    "for i in range(10):\n",
    "    print (\"Random seed %s\" % i)\n",
    "    np.random.seed(seed=i)\n",
    "    X_seed = np.random.normal(0, 1, size)\n",
    "    X1 = X_seed + np.random.normal(0, .1, size)\n",
    "    X2 = X_seed + np.random.normal(0, .1, size)\n",
    "    X3 = X_seed + np.random.normal(0, .1, size)\n",
    "    Y = X1 + X2 + X3 + np.random.normal(0, 1, size)\n",
    "    X = np.array([X1, X2, X3]).T\n",
    " \n",
    " \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X,Y)\n",
    "    print (\"Linear model:\", pretty_print_linear(lr.coef_))\n",
    " \n",
    "    ridge = Ridge(alpha=10)\n",
    "    ridge.fit(X,Y)\n",
    "    print (\"Ridge model:\", pretty_print_linear(ridge.coef_))\n",
    "    print ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "[(0.45140000000000002, 'RM'), (0.3387, 'LSTAT'), (0.0654, 'DIS'), (0.051200000000000002, 'CRIM'), (0.021499999999999998, 'NOX'), (0.0166, 'TAX'), (0.0147, 'B'), (0.013899999999999999, 'PTRATIO'), (0.0132, 'AGE'), (0.0061999999999999998, 'RAD'), (0.0054000000000000003, 'INDUS'), (0.0011000000000000001, 'ZN'), (0.00059999999999999995, 'CHAS')]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "#Load boston housing dataset as an example\n",
    "boston = load_boston()\n",
    "X = boston[\"data\"]\n",
    "Y = boston[\"target\"]\n",
    "names = boston[\"feature_names\"]\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X, Y)\n",
    "print (\"Features sorted by their score:\")\n",
    "print (sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), names), \n",
    "             reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "[(1.0, 'RM'), (1.0, 'PTRATIO'), (1.0, 'LSTAT'), (0.64500000000000002, 'B'), (0.62, 'CHAS'), (0.44, 'CRIM'), (0.42999999999999999, 'TAX'), (0.23000000000000001, 'DIS'), (0.22, 'NOX'), (0.13500000000000001, 'INDUS'), (0.029999999999999999, 'ZN'), (0.029999999999999999, 'RAD'), (0.014999999999999999, 'AGE')]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RandomizedLasso\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    " \n",
    "#using the Boston housing data. \n",
    "#Data gets scaled automatically by sklearn's implementation\n",
    "X = boston[\"data\"]\n",
    "Y = boston[\"target\"]\n",
    "names = boston[\"feature_names\"]\n",
    " \n",
    "rlasso = RandomizedLasso(alpha=0.025)\n",
    "rlasso.fit(X, Y)\n",
    " \n",
    "print (\"Features sorted by their score:\")\n",
    "print (sorted(zip(map(lambda x: round(x, 4), rlasso.scores_), \n",
    "                 names), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their rank:\n",
      "[(1, 'NOX'), (2, 'RM'), (3, 'CHAS'), (4, 'PTRATIO'), (5, 'DIS'), (6, 'LSTAT'), (7, 'RAD'), (8, 'CRIM'), (9, 'INDUS'), (10, 'ZN'), (11, 'TAX'), (12, 'B'), (13, 'AGE')]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    " \n",
    "boston = load_boston()\n",
    "X = boston[\"data\"]\n",
    "Y = boston[\"target\"]\n",
    "names = boston[\"feature_names\"]\n",
    " \n",
    "#use linear regression as the model\n",
    "lr = LinearRegression()\n",
    "#rank all features, i.e continue the elimination until the last one\n",
    "rfe = RFE(lr, n_features_to_select=1)\n",
    "rfe.fit(X,Y)\n",
    " \n",
    "print (\"Features sorted by their rank:\")\n",
    "print (sorted(zip(map(lambda x: round(x, 4), rfe.ranking_), names)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "[(0.73909999999999998, 'LSTAT'), (0.53280000000000005, 'RM'), (0.081000000000000003, 'DIS'), (0.042799999999999998, 'NOX'), (0.037699999999999997, 'CRIM'), (0.026100000000000002, 'PTRATIO'), (0.015900000000000001, 'TAX'), (0.011299999999999999, 'AGE'), (0.0060000000000000001, 'INDUS'), (0.0051000000000000004, 'B'), (0.0035000000000000001, 'RAD'), (0.0001, 'ZN'), (0.0001, 'CHAS')]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "from sklearn.metrics import r2_score\n",
    "from collections import defaultdict\n",
    "\n",
    "#Load boston housing dataset as an example\n",
    "boston = load_boston()\n",
    "X = boston[\"data\"]\n",
    "Y = boston[\"target\"]\n",
    "names = boston[\"feature_names\"]\n",
    "rf = RandomForestRegressor()\n",
    "scores = defaultdict(list)\n",
    " \n",
    "#crossvalidate the scores on a number of different random splits of the data\n",
    "for train_idx, test_idx in ShuffleSplit(len(X), 100, .3):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    Y_train, Y_test = Y[train_idx], Y[test_idx]\n",
    "    r = rf.fit(X_train, Y_train)\n",
    "    acc = r2_score(Y_test, rf.predict(X_test))\n",
    "    for i in range(X.shape[1]):\n",
    "        X_t = X_test.copy()\n",
    "        np.random.shuffle(X_t[:, i])\n",
    "        shuff_acc = r2_score(Y_test, rf.predict(X_t))\n",
    "        scores[names[i]].append((acc-shuff_acc)/acc)\n",
    "print (\"Features sorted by their score:\")\n",
    "print (sorted([(round(np.mean(score), 4), feat) for\n",
    "              feat, score in scores.items()], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tim.wu/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCorr.\tLasso\tLinear reg\tMIC\tRF\tRFE\tRidge\tStability\tMean\n",
      "x1\t0.3\t0.79\t1.0\t0.39\t0.55\t1.0\t0.77\t0.77\t0.7\n",
      "x2\t0.44\t0.83\t0.56\t0.61\t0.67\t1.0\t0.75\t0.72\t0.7\n",
      "x3\t0.0\t0.0\t0.5\t0.34\t0.13\t1.0\t0.05\t0.0\t0.25\n",
      "x4\t1.0\t1.0\t0.57\t1.0\t0.56\t1.0\t1.0\t1.0\t0.89\n",
      "x5\t0.1\t0.51\t0.27\t0.2\t0.29\t0.78\t0.88\t0.55\t0.45\n",
      "x6\t0.0\t0.0\t0.02\t0.0\t0.01\t0.44\t0.05\t0.0\t0.06\n",
      "x7\t0.01\t0.0\t0.0\t0.07\t0.02\t0.0\t0.01\t0.0\t0.01\n",
      "x8\t0.02\t0.0\t0.03\t0.05\t0.01\t0.56\t0.09\t0.0\t0.1\n",
      "x9\t0.01\t0.0\t0.0\t0.09\t0.01\t0.11\t0.0\t0.0\t0.03\n",
      "x10\t0.0\t0.0\t0.01\t0.04\t0.0\t0.33\t0.01\t0.0\t0.05\n",
      "x11\t0.29\t0.0\t0.6\t0.43\t0.39\t1.0\t0.59\t0.37\t0.46\n",
      "x12\t0.44\t0.0\t0.14\t0.71\t0.35\t0.67\t0.68\t0.47\t0.43\n",
      "x13\t0.0\t0.0\t0.48\t0.23\t0.07\t0.89\t0.02\t0.0\t0.21\n",
      "x14\t0.99\t0.16\t0.0\t1.0\t1.0\t0.22\t0.95\t0.62\t0.62\n"
     ]
    }
   ],
   "source": [
    "#http://blog.datadive.net\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import (LinearRegression, Ridge, \n",
    "                                  Lasso, RandomizedLasso)\n",
    "from sklearn.feature_selection import RFE, f_regression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "from minepy import MINE\n",
    " \n",
    "np.random.seed(0)\n",
    " \n",
    "size = 750\n",
    "X = np.random.uniform(0, 1, (size, 14))\n",
    " \n",
    "#\"Friedamn #1” regression problem\n",
    "Y = (10 * np.sin(np.pi*X[:,0]*X[:,1]) + 20*(X[:,2] - .5)**2 +\n",
    "     10*X[:,3] + 5*X[:,4] + np.random.normal(0,1))\n",
    "#Add 3 additional correlated variables (correlated with X1-X3)\n",
    "X[:,10:] = X[:,:4] + np.random.normal(0, .025, (size,4))\n",
    " \n",
    "names = [\"x%s\" % i for i in range(1,15)]\n",
    " \n",
    "ranks = {}\n",
    " \n",
    "def rank_to_dict(ranks, names, order=1):\n",
    "    minmax = MinMaxScaler()\n",
    "    ranks = minmax.fit_transform(order*np.array([ranks]).T).T[0]\n",
    "    ranks = map(lambda x: round(x, 2), ranks)\n",
    "    return dict(zip(names, ranks ))\n",
    " \n",
    "lr = LinearRegression(normalize=True)\n",
    "lr.fit(X, Y)\n",
    "ranks[\"Linear reg\"] = rank_to_dict(np.abs(lr.coef_), names)\n",
    " \n",
    "ridge = Ridge(alpha=7)\n",
    "ridge.fit(X, Y)\n",
    "ranks[\"Ridge\"] = rank_to_dict(np.abs(ridge.coef_), names)\n",
    " \n",
    " \n",
    "lasso = Lasso(alpha=.05)\n",
    "lasso.fit(X, Y)\n",
    "ranks[\"Lasso\"] = rank_to_dict(np.abs(lasso.coef_), names)\n",
    " \n",
    " \n",
    "rlasso = RandomizedLasso(alpha=0.04)\n",
    "rlasso.fit(X, Y)\n",
    "ranks[\"Stability\"] = rank_to_dict(np.abs(rlasso.scores_), names)\n",
    " \n",
    "#stop the search when 5 features are left (they will get equal scores)\n",
    "rfe = RFE(lr, n_features_to_select=5)\n",
    "rfe.fit(X,Y)\n",
    "ranks[\"RFE\"] = rank_to_dict(rfe.ranking_, names, order=-1)\n",
    " \n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X,Y)\n",
    "ranks[\"RF\"] = rank_to_dict(rf.feature_importances_, names)\n",
    " \n",
    " \n",
    "f, pval  = f_regression(X, Y, center=True)\n",
    "ranks[\"Corr.\"] = rank_to_dict(f, names)\n",
    " \n",
    "mine = MINE()\n",
    "mic_scores = []\n",
    "for i in range(X.shape[1]):\n",
    "    mine.compute_score(X[:,i], Y)\n",
    "    m = mine.mic()\n",
    "    mic_scores.append(m)\n",
    " \n",
    "ranks[\"MIC\"] = rank_to_dict(mic_scores, names) \n",
    " \n",
    " \n",
    "r = {}\n",
    "for name in names:\n",
    "    r[name] = round(np.mean([ranks[method][name] \n",
    "                             for method in ranks.keys()]), 2)\n",
    " \n",
    "methods = sorted(ranks.keys())\n",
    "ranks[\"Mean\"] = r\n",
    "methods.append(\"Mean\")\n",
    " \n",
    "print (\"\\t%s\" % \"\\t\".join(methods))\n",
    "for name in names:\n",
    "    print (\"%s\\t%s\" % (name, \"\\t\".join(map(str, \n",
    "                         [ranks[method][name] for method in methods]))))\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
