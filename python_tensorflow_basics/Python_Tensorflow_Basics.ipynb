{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 0.13925862] [ 0.40262067]\n",
      "20 [ 0.09667291] [ 0.30190626]\n",
      "40 [ 0.09924743] [ 0.30043119]\n",
      "60 [ 0.09982978] [ 0.30009755]\n",
      "80 [ 0.0999615] [ 0.30002207]\n",
      "100 [ 0.09999131] [ 0.30000499]\n",
      "120 [ 0.09999803] [ 0.30000114]\n",
      "140 [ 0.09999957] [ 0.30000025]\n",
      "160 [ 0.09999991] [ 0.30000007]\n",
      "180 [ 0.09999991] [ 0.30000007]\n",
      "200 [ 0.09999991] [ 0.30000007]\n"
     ]
    }
   ],
   "source": [
    "# Linear Equation \n",
    "\n",
    "# create data\n",
    "x_data = np.random.rand(100).astype(np.float32)\n",
    "y_data = x_data*0.1 + 0.3\n",
    "\n",
    "### create tensorflow structure start ###\n",
    "Weights = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "biases = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "y = Weights*x_data + biases #Logistic Classifier \n",
    "\n",
    "loss = tf.reduce_mean(tf.square(y-y_data))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "### create tensorflow structure end ###\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)          # initalize the tensorflow session\n",
    "\n",
    "for step in range(201):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:\n",
    "        print(step, sess.run(Weights), sess.run(biases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12]]\n",
      "[[12]]\n"
     ]
    }
   ],
   "source": [
    "# Product of two matrixs\n",
    "# Use Session\n",
    "matrix1 = tf.constant([[3, 3]])\n",
    "matrix2 = tf.constant([[2],\n",
    "                       [2]])\n",
    "product = tf.matmul(matrix1, matrix2)  # matrix multiply np.dot(m1, m2)\n",
    "\n",
    "# method 1\n",
    "sess = tf.Session()\n",
    "result = sess.run(product)\n",
    "print(result)\n",
    "sess.close()\n",
    "\n",
    "# method 2\n",
    "with tf.Session() as sess:\n",
    "    result2 = sess.run(product)\n",
    "    print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Learn how to set Variables\n",
    "\n",
    "state = tf.Variable(0, name='counter')\n",
    "#print(state.name)\n",
    "one = tf.constant(1)\n",
    "\n",
    "new_value = tf.add(state, one)\n",
    "update = tf.assign(state, new_value)\n",
    "\n",
    "init = tf.initialize_all_variables()  # must have if define variable\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for _ in range(3):\n",
    "        sess.run(update)\n",
    "        print(sess.run(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 14.]\n"
     ]
    }
   ],
   "source": [
    "# Learn how to use placeholder\n",
    "\n",
    "input1 = tf.placeholder(tf.float32)\n",
    "input2 = tf.placeholder(tf.float32)\n",
    "ouput = tf.mul(input1, input2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(ouput, feed_dict={input1: [7.], input2: [2.]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tensorflow activation functions\n",
    "# def add_layer function\n",
    "\n",
    "def add_layer(inputs, in_size, out_size, activation_function=None):\n",
    "    # add one more layer and return the output of this layer\n",
    "    Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)\n",
    "    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.518447\n",
      "0.0124032\n",
      "0.00940049\n",
      "0.00811168\n",
      "0.00751376\n",
      "0.00704649\n",
      "0.00669554\n",
      "0.00641924\n",
      "0.00618481\n",
      "0.00597769\n",
      "0.00578448\n",
      "0.00560544\n",
      "0.0054435\n",
      "0.00530177\n",
      "0.00517555\n",
      "0.00506121\n",
      "0.00494818\n",
      "0.00483837\n",
      "0.00473867\n",
      "0.00464359\n"
     ]
    }
   ],
   "source": [
    "# Make up some real data\n",
    "x_data = np.linspace(-1,1,300)[:, np.newaxis]\n",
    "noise = np.random.normal(0, 0.05, x_data.shape)\n",
    "y_data = np.square(x_data) - 0.5 + noise\n",
    "\n",
    "# define placeholder for inputs to network\n",
    "xs = tf.placeholder(tf.float32, [None, 1])\n",
    "ys = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "# add hidden layer\n",
    "l1 = add_layer(xs, 1, 10, activation_function=tf.nn.relu)\n",
    "\n",
    "# add output layer\n",
    "prediction = add_layer(l1, 10, 1, activation_function=None)\n",
    "\n",
    "# the error between prediciton and real data\n",
    "loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction),\n",
    "                     reduction_indices=[1]))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "# Initialize step\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(1000):\n",
    "    # training\n",
    "    sess.run(train_step, feed_dict={xs: x_data, ys: y_data})\n",
    "    if i % 50 == 0:\n",
    "        # to see the step improvement\n",
    "        print(sess.run(loss, feed_dict={xs: x_data, ys: y_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhcAAAFkCAYAAACThxm6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niwszMzNLysWFmZmZJfUfZPmgLRfykJMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1146c7cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the real data\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.scatter(x_data, y_data)\n",
    "plt.ion()\n",
    "plt.show()\n",
    "\n",
    "for i in range(1000):\n",
    "    # training\n",
    "    sess.run(train_step, feed_dict={xs: x_data, ys: y_data})\n",
    "    if i % 50 == 0:\n",
    "        # to visualize the result and improvement\n",
    "        try:\n",
    "            ax.lines.remove(lines[0])\n",
    "        except Exception:\n",
    "            pass\n",
    "        prediction_value = sess.run(prediction, feed_dict={xs: x_data})\n",
    "        # plot the prediction\n",
    "        lines = ax.plot(x_data, prediction_value, 'r-', lw=5)\n",
    "        plt.pause(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How to use Tensorboard\n",
    "# Regression\n",
    "\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def add_layer(inputs, in_size, out_size, activation_function=None):\n",
    "    # add one more layer and return the output of this layer\n",
    "    with tf.name_scope('layer'):\n",
    "        with tf.name_scope('weights'):\n",
    "            Weights = tf.Variable(tf.random_normal([in_size, out_size]), name='W')\n",
    "        with tf.name_scope('biases'):\n",
    "            biases = tf.Variable(tf.zeros([1, out_size]) + 0.1, name='b')\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            Wx_plus_b = tf.add(tf.matmul(inputs, Weights), biases)\n",
    "        if activation_function is None:\n",
    "            outputs = Wx_plus_b\n",
    "        else:\n",
    "            outputs = activation_function(Wx_plus_b, )\n",
    "        return outputs\n",
    "\n",
    "\n",
    "# define placeholder for inputs to network\n",
    "with tf.name_scope('inputs'):\n",
    "    xs = tf.placeholder(tf.float32, [None, 1], name='x_input')\n",
    "    ys = tf.placeholder(tf.float32, [None, 1], name='y_input')\n",
    "\n",
    "# add hidden layer\n",
    "l1 = add_layer(xs, 1, 10, activation_function=tf.nn.relu)\n",
    "# add output layer\n",
    "prediction = add_layer(l1, 10, 1, activation_function=None)\n",
    "\n",
    "# the error between prediciton and real data\n",
    "with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction),\n",
    "                                        reduction_indices=[1]))\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "sess = tf.Session()\n",
    "writer = tf.train.SummaryWriter(\"logs/\", sess.graph)\n",
    "# important step\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "# direct to the local dir and run this in terminal:\n",
    "# $ tensorboard --logdir=logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "0.1382\n",
      "0.6202\n",
      "0.7271\n",
      "0.7817\n",
      "0.7999\n",
      "0.8227\n",
      "0.8345\n",
      "0.8356\n",
      "0.8436\n",
      "0.8506\n",
      "0.8523\n",
      "0.8528\n",
      "0.8624\n",
      "0.8639\n",
      "0.8679\n",
      "0.8699\n",
      "0.8714\n",
      "0.8725\n",
      "0.8802\n",
      "0.8745\n"
     ]
    }
   ],
   "source": [
    "# Classification \n",
    "\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# number 1 to 10 data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "def add_layer(inputs, in_size, out_size, activation_function=None,):\n",
    "    # add one more layer and return the output of this layer\n",
    "    Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1,)\n",
    "    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b,)\n",
    "    return outputs\n",
    "\n",
    "def compute_accuracy(v_xs, v_ys):\n",
    "    global prediction\n",
    "    y_pre = sess.run(prediction, feed_dict={xs: v_xs})\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(v_ys,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    result = sess.run(accuracy, feed_dict={xs: v_xs, ys: v_ys})\n",
    "    return result\n",
    "\n",
    "# define placeholder for inputs to network\n",
    "xs = tf.placeholder(tf.float32, [None, 784]) # 28x28\n",
    "ys = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# add output layer\n",
    "prediction = add_layer(xs, 784, 10,  activation_function=tf.nn.softmax)\n",
    "\n",
    "# the error between prediction and real data\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction),\n",
    "                                              reduction_indices=[1]))       # loss\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "sess = tf.Session()\n",
    "# important step\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "for i in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={xs: batch_xs, ys: batch_ys})\n",
    "    if i % 50 == 0:\n",
    "        print(compute_accuracy(\n",
    "            mnist.test.images, mnist.test.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tim.wu/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Drop out to reduce overfitting\n",
    "\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# load data\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "y = LabelBinarizer().fit_transform(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3)\n",
    "\n",
    "\n",
    "def add_layer(inputs, in_size, out_size, layer_name, activation_function=None, ):\n",
    "    # add one more layer and return the output of this layer\n",
    "    Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1, )\n",
    "    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n",
    "    # here to dropout\n",
    "    Wx_plus_b = tf.nn.dropout(Wx_plus_b, keep_prob)\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b, )\n",
    "    tf.histogram_summary(layer_name + '/outputs', outputs)\n",
    "    return outputs\n",
    "\n",
    "\n",
    "# define placeholder for inputs to network\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "xs = tf.placeholder(tf.float32, [None, 64])  # 8x8\n",
    "ys = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# add output layer\n",
    "l1 = add_layer(xs, 64, 50, 'l1', activation_function=tf.nn.tanh)\n",
    "prediction = add_layer(l1, 50, 10, 'l2', activation_function=tf.nn.softmax)\n",
    "\n",
    "# the loss between prediction and real data\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction),\n",
    "                                              reduction_indices=[1]))  # loss\n",
    "tf.scalar_summary('loss', cross_entropy)\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "sess = tf.Session()\n",
    "merged = tf.merge_all_summaries()\n",
    "# summary writer goes in here\n",
    "train_writer = tf.train.SummaryWriter(\"logs/train\", sess.graph)\n",
    "test_writer = tf.train.SummaryWriter(\"logs/test\", sess.graph)\n",
    "\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "for i in range(500):\n",
    "    # here to determine the keeping probability\n",
    "    sess.run(train_step, feed_dict={xs: X_train, ys: y_train, keep_prob: 0.5})\n",
    "    if i % 50 == 0:\n",
    "        # record loss\n",
    "        train_result = sess.run(merged, feed_dict={xs: X_train, ys: y_train, keep_prob: 1})\n",
    "        test_result = sess.run(merged, feed_dict={xs: X_test, ys: y_test, keep_prob: 1})\n",
    "        train_writer.add_summary(train_result, i)\n",
    "        test_writer.add_summary(test_result, i)\n",
    "        \n",
    "# direct to the local dir and run this in terminal:\n",
    "# $tensorboard --logdir=logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "0.1693\n",
      "0.7688\n",
      "0.8672\n",
      "0.9073\n",
      "0.9276\n",
      "0.9287\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2f16b1569e65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         print(compute_accuracy(\n",
      "\u001b[0;32m/Users/tim.wu/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tim.wu/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 915\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    916\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tim.wu/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 965\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/tim.wu/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    970\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tim.wu/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    952\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    953\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# number 1 to 10 data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "def compute_accuracy(v_xs, v_ys):\n",
    "    global prediction\n",
    "    y_pre = sess.run(prediction, feed_dict={xs: v_xs, keep_prob: 1})\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(v_ys,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    result = sess.run(accuracy, feed_dict={xs: v_xs, ys: v_ys, keep_prob: 1})\n",
    "    return result\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    # stride [1, x_movement, y_movement, 1]\n",
    "    # Must have strides[0] = strides[3] = 1\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    # stride [1, x_movement, y_movement, 1]\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "# define placeholder for inputs to network\n",
    "xs = tf.placeholder(tf.float32, [None, 784]) # 28x28\n",
    "ys = tf.placeholder(tf.float32, [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "x_image = tf.reshape(xs, [-1, 28, 28, 1]) # 1 because black and white.\n",
    "# print(x_image.shape)  # [n_samples, 28,28,1]\n",
    "\n",
    "## conv1 layer ##\n",
    "W_conv1 = weight_variable([5,5, 1,32]) # patch 5x5, in size 1, out size 32\n",
    "b_conv1 = bias_variable([32])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1) # output size 28x28x32\n",
    "h_pool1 = max_pool_2x2(h_conv1)                          # output size 14x14x32\n",
    "\n",
    "## conv2 layer ##\n",
    "W_conv2 = weight_variable([5,5, 32,64]) # patch 5x5, in size 32, out size 64\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2) # output size 14x14x64\n",
    "h_pool2 = max_pool_2x2(h_conv2)                          # output size 7x7x64\n",
    "\n",
    "## func1 layer ##\n",
    "W_fc1 = weight_variable([7*7*64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "# [n_samples, 7, 7, 64] ->> [n_samples, 7*7*64]\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "## func2 layer ##\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "prediction = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "# the error between prediction and real data\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction),\n",
    "                                              reduction_indices=[1]))       # loss\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "sess = tf.Session()\n",
    "# important step\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "for i in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={xs: batch_xs, ys: batch_ys, keep_prob: 0.5})\n",
    "    if i % 50 == 0:\n",
    "        print(compute_accuracy(\n",
    "            mnist.test.images, mnist.test.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save to path:  my_net/save_net.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow - Saver\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "## Save to file\n",
    "## remember to define the same dtype and shape when restore\n",
    "W = tf.Variable([[1,2,3],[3,4,5]], dtype=tf.float32, name='weights')\n",
    "b = tf.Variable([[1,2,3]], dtype=tf.float32, name='biases')\n",
    "##\n",
    "init= tf.initialize_all_variables()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    save_path = saver.save(sess, \"my_net/save_net.ckpt\")\n",
    "    print(\"Save to path: \", save_path)\n",
    "\n",
    "## python tensor_flow_restore_variables.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "0.320312\n",
      "0.742188\n",
      "0.734375\n",
      "0.773438\n",
      "0.882812\n",
      "0.757812\n",
      "0.875\n",
      "0.96875\n",
      "0.890625\n",
      "0.921875\n",
      "0.898438\n",
      "0.929688\n",
      "0.929688\n",
      "0.9375\n",
      "0.96875\n",
      "0.960938\n",
      "0.9375\n",
      "0.921875\n",
      "0.929688\n",
      "0.9375\n",
      "0.9375\n",
      "0.945312\n",
      "0.96875\n",
      "0.9375\n",
      "0.953125\n",
      "0.90625\n",
      "0.976562\n",
      "0.960938\n",
      "0.953125\n",
      "0.960938\n",
      "0.984375\n",
      "0.96875\n",
      "0.976562\n",
      "0.96875\n",
      "0.945312\n",
      "0.945312\n",
      "0.992188\n",
      "0.984375\n",
      "0.992188\n",
      "0.984375\n"
     ]
    }
   ],
   "source": [
    "## LSTM RNN Classifcation\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# set random seed for comparing the two result calculations\n",
    "tf.set_random_seed(1)\n",
    "\n",
    "# this is data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "# hyperparameters\n",
    "lr = 0.001\n",
    "training_iters = 100000\n",
    "batch_size = 128\n",
    "\n",
    "n_inputs = 28   # MNIST data input (img shape: 28*28)\n",
    "n_steps = 28    # time steps\n",
    "n_hidden_units = 128   # neurons in hidden layer\n",
    "n_classes = 10      # MNIST classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    # (28, 128)\n",
    "    'in': tf.Variable(tf.random_normal([n_inputs, n_hidden_units])),\n",
    "    # (128, 10)\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_units, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    # (128, )\n",
    "    'in': tf.Variable(tf.constant(0.1, shape=[n_hidden_units, ])),\n",
    "    # (10, )\n",
    "    'out': tf.Variable(tf.constant(0.1, shape=[n_classes, ]))\n",
    "}\n",
    "\n",
    "\n",
    "def RNN(X, weights, biases):\n",
    "    # hidden layer for input to cell\n",
    "    ########################################\n",
    "\n",
    "    # transpose the inputs shape from\n",
    "    # X ==> (128 batch * 28 steps, 28 inputs)\n",
    "    X = tf.reshape(X, [-1, n_inputs])\n",
    "\n",
    "    # into hidden\n",
    "    # X_in = (128 batch * 28 steps, 128 hidden)\n",
    "    X_in = tf.matmul(X, weights['in']) + biases['in']\n",
    "    # X_in ==> (128 batch, 28 steps, 128 hidden)\n",
    "    X_in = tf.reshape(X_in, [-1, n_steps, n_hidden_units])\n",
    "\n",
    "    # cell\n",
    "    ##########################################\n",
    "\n",
    "    # basic LSTM Cell.\n",
    "    lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden_units, forget_bias=1.0, state_is_tuple=True)\n",
    "    # lstm cell is divided into two parts (c_state, h_state)\n",
    "    _init_state = lstm_cell.zero_state(batch_size, dtype=tf.float32)\n",
    "\n",
    "    # You have 2 options for following step.\n",
    "    # 1: tf.nn.rnn(cell, inputs);\n",
    "    # 2: tf.nn.dynamic_rnn(cell, inputs).\n",
    "    # If use option 1, you have to modified the shape of X_in, go and check out this:\n",
    "    # https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py\n",
    "    # In here, we go for option 2.\n",
    "    # dynamic_rnn receive Tensor (batch, steps, inputs) or (steps, batch, inputs) as X_in.\n",
    "    # Make sure the time_major is changed accordingly.\n",
    "    outputs, final_state = tf.nn.dynamic_rnn(lstm_cell, X_in, initial_state=_init_state, time_major=False)\n",
    "\n",
    "    # hidden layer for output as the final results\n",
    "    #############################################\n",
    "    # results = tf.matmul(final_state[1], weights['out']) + biases['out']\n",
    "\n",
    "    # # or\n",
    "    # unpack to list [(batch, outputs)..] * steps\n",
    "    #outputs = tf.unpack(tf.transpose(outputs, [1, 0, 2]))    # states is the last outputs\n",
    "    #results = tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "pred = RNN(x, weights, biases)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "train_op = tf.train.AdamOptimizer(lr).minimize(cost)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 0\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        batch_xs = batch_xs.reshape([batch_size, n_steps, n_inputs])\n",
    "        sess.run([train_op], feed_dict={\n",
    "            x: batch_xs,\n",
    "            y: batch_ys,\n",
    "        })\n",
    "        if step % 20 == 0:\n",
    "            print(sess.run(accuracy, feed_dict={\n",
    "            x: batch_xs,\n",
    "            y: batch_ys,\n",
    "        }))\n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Tensor name \"biases_5\" not found in checkpoint files my_net/save_net.ckpt\n\t [[Node: save_4/restore_slice_5 = RestoreSlice[dt=DT_FLOAT, preferred_shard=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_4/Const_0, save_4/restore_slice_5/tensor_name, save_4/restore_slice_5/shape_and_slice)]]\n\nCaused by op 'save_4/restore_slice_5', defined at:\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-ce87f897ce51>\", line 9, in <module>\n    saver = tf.train.Saver()\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 986, in __init__\n    self.build()\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1015, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 620, in build\n    restore_sequentially, reshape)\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 357, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 270, in restore_op\n    preferred_shard=preferred_shard))\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/io_ops.py\", line 204, in _restore_slice\n    preferred_shard, name=name)\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 359, in _restore_slice\n    preferred_shard=preferred_shard, name=name)\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 749, in apply_op\n    op_def=op_def)\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2380, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1298, in __init__\n    self._traceback = _extract_stack()\n\nNotFoundError (see above for traceback): Tensor name \"biases_5\" not found in checkpoint files my_net/save_net.ckpt\n\t [[Node: save_4/restore_slice_5 = RestoreSlice[dt=DT_FLOAT, preferred_shard=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_4/Const_0, save_4/restore_slice_5/tensor_name, save_4/restore_slice_5/shape_and_slice)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/Users/tim.wu/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tim.wu/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    953\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tim.wu/anaconda3/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tim.wu/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/errors.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    462\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    464\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Tensor name \"biases_5\" not found in checkpoint files my_net/save_net.ckpt\n\t [[Node: save_4/restore_slice_5 = RestoreSlice[dt=DT_FLOAT, preferred_shard=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_4/Const_0, save_4/restore_slice_5/tensor_name, save_4/restore_slice_5/shape_and_slice)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d061009febd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"my_net/save_net.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"weights:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"biases:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tim.wu/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1345\u001b[0;31m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tim.wu/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tim.wu/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 915\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    916\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tim.wu/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 965\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/tim.wu/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Tensor name \"biases_5\" not found in checkpoint files my_net/save_net.ckpt\n\t [[Node: save_4/restore_slice_5 = RestoreSlice[dt=DT_FLOAT, preferred_shard=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_4/Const_0, save_4/restore_slice_5/tensor_name, save_4/restore_slice_5/shape_and_slice)]]\n\nCaused by op 'save_4/restore_slice_5', defined at:\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-ce87f897ce51>\", line 9, in <module>\n    saver = tf.train.Saver()\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 986, in __init__\n    self.build()\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1015, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 620, in build\n    restore_sequentially, reshape)\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 357, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 270, in restore_op\n    preferred_shard=preferred_shard))\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/io_ops.py\", line 204, in _restore_slice\n    preferred_shard, name=name)\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 359, in _restore_slice\n    preferred_shard=preferred_shard, name=name)\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 749, in apply_op\n    op_def=op_def)\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2380, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/tim.wu/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1298, in __init__\n    self._traceback = _extract_stack()\n\nNotFoundError (see above for traceback): Tensor name \"biases_5\" not found in checkpoint files my_net/save_net.ckpt\n\t [[Node: save_4/restore_slice_5 = RestoreSlice[dt=DT_FLOAT, preferred_shard=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_4/Const_0, save_4/restore_slice_5/tensor_name, save_4/restore_slice_5/shape_and_slice)]]\n"
     ]
    }
   ],
   "source": [
    "# LSTRNN Regression\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "BATCH_START = 0\n",
    "TIME_STEPS = 20\n",
    "BATCH_SIZE = 50\n",
    "INPUT_SIZE = 1\n",
    "OUTPUT_SIZE = 1\n",
    "CELL_SIZE = 10\n",
    "LR = 0.006\n",
    "\n",
    "\n",
    "def get_batch():\n",
    "    global BATCH_START, TIME_STEPS\n",
    "    # xs shape (50batch, 20steps)\n",
    "    xs = np.arange(BATCH_START, BATCH_START+TIME_STEPS*BATCH_SIZE).reshape((BATCH_SIZE, TIME_STEPS)) / (10*np.pi)\n",
    "    seq = np.sin(xs)\n",
    "    res = np.cos(xs)\n",
    "    BATCH_START += TIME_STEPS\n",
    "    # plt.plot(xs[0, :], res[0, :], 'r', xs[0, :], seq[0, :], 'b--')\n",
    "    # plt.show()\n",
    "    # returned seq, res and xs: shape (batch, step, input)\n",
    "    return [seq[:, :, np.newaxis], res[:, :, np.newaxis], xs]\n",
    "\n",
    "\n",
    "class LSTMRNN(object):\n",
    "    def __init__(self, n_steps, input_size, output_size, cell_size, batch_size):\n",
    "        self.n_steps = n_steps\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.cell_size = cell_size\n",
    "        self.batch_size = batch_size\n",
    "        with tf.name_scope('inputs'):\n",
    "            self.xs = tf.placeholder(tf.float32, [None, n_steps, input_size], name='xs')\n",
    "            self.ys = tf.placeholder(tf.float32, [None, n_steps, output_size], name='ys')\n",
    "        with tf.variable_scope('in_hidden'):\n",
    "            self.add_input_layer()\n",
    "        with tf.variable_scope('LSTM_cell'):\n",
    "            self.add_cell()\n",
    "        with tf.variable_scope('out_hidden'):\n",
    "            self.add_output_layer()\n",
    "        with tf.name_scope('cost'):\n",
    "            self.compute_cost()\n",
    "        with tf.name_scope('train'):\n",
    "            self.train_op = tf.train.AdamOptimizer(LR).minimize(self.cost)\n",
    "\n",
    "    def add_input_layer(self,):\n",
    "        l_in_x = tf.reshape(self.xs, [-1, self.input_size], name='2_2D')  # (batch*n_step, in_size)\n",
    "        # Ws (in_size, cell_size)\n",
    "        Ws_in = self._weight_variable([self.input_size, self.cell_size])\n",
    "        # bs (cell_size, )\n",
    "        bs_in = self._bias_variable([self.cell_size,])\n",
    "        # l_in_y = (batch * n_steps, cell_size)\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            l_in_y = tf.matmul(l_in_x, Ws_in) + bs_in\n",
    "        # reshape l_in_y ==> (batch, n_steps, cell_size)\n",
    "        self.l_in_y = tf.reshape(l_in_y, [-1, self.n_steps, self.cell_size], name='2_3D')\n",
    "\n",
    "    def add_cell(self):\n",
    "        lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(self.cell_size, forget_bias=1.0, state_is_tuple=True)\n",
    "        with tf.name_scope('initial_state'):\n",
    "            self.cell_init_state = lstm_cell.zero_state(self.batch_size, dtype=tf.float32)\n",
    "        self.cell_outputs, self.cell_final_state = tf.nn.dynamic_rnn(\n",
    "            lstm_cell, self.l_in_y, initial_state=self.cell_init_state, time_major=False)\n",
    "\n",
    "    def add_output_layer(self):\n",
    "        # shape = (batch * steps, cell_size)\n",
    "        l_out_x = tf.reshape(self.cell_outputs, [-1, self.cell_size], name='2_2D')\n",
    "        Ws_out = self._weight_variable([self.cell_size, self.output_size])\n",
    "        bs_out = self._bias_variable([self.output_size, ])\n",
    "        # shape = (batch * steps, output_size)\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            self.pred = tf.matmul(l_out_x, Ws_out) + bs_out\n",
    "\n",
    "    def compute_cost(self):\n",
    "        losses = tf.nn.seq2seq.sequence_loss_by_example(\n",
    "            [tf.reshape(self.pred, [-1], name='reshape_pred')],\n",
    "            [tf.reshape(self.ys, [-1], name='reshape_target')],\n",
    "            [tf.ones([self.batch_size * self.n_steps], dtype=tf.float32)],\n",
    "            average_across_timesteps=True,\n",
    "            softmax_loss_function=self.ms_error,\n",
    "            name='losses'\n",
    "        )\n",
    "        with tf.name_scope('average_cost'):\n",
    "            self.cost = tf.div(\n",
    "                tf.reduce_sum(losses, name='losses_sum'),\n",
    "                self.batch_size,\n",
    "                name='average_cost')\n",
    "            tf.scalar_summary('cost', self.cost)\n",
    "\n",
    "    def ms_error(self, y_pre, y_target):\n",
    "        return tf.square(tf.sub(y_pre, y_target))\n",
    "\n",
    "    def _weight_variable(self, shape, name='weights'):\n",
    "        initializer = tf.random_normal_initializer(mean=0., stddev=1.,)\n",
    "        return tf.get_variable(shape=shape, initializer=initializer, name=name)\n",
    "\n",
    "    def _bias_variable(self, shape, name='biases'):\n",
    "        initializer = tf.constant_initializer(0.1)\n",
    "        return tf.get_variable(name=name, shape=shape, initializer=initializer)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = LSTMRNN(TIME_STEPS, INPUT_SIZE, OUTPUT_SIZE, CELL_SIZE, BATCH_SIZE)\n",
    "    sess = tf.Session()\n",
    "    merged = tf.merge_all_summaries()\n",
    "    writer = tf.train.SummaryWriter(\"logs\", sess.graph)\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    # relocate to the local dir and run this line to view it on Chrome (http://0.0.0.0:6006/):\n",
    "    # $ tensorboard --logdir='logs'\n",
    "\n",
    "    plt.ion()\n",
    "    plt.show()\n",
    "    for i in range(200):\n",
    "        seq, res, xs = get_batch()\n",
    "        if i == 0:\n",
    "            feed_dict = {\n",
    "                    model.xs: seq,\n",
    "                    model.ys: res,\n",
    "                    # create initial state\n",
    "            }\n",
    "        else:\n",
    "            feed_dict = {\n",
    "                model.xs: seq,\n",
    "                model.ys: res,\n",
    "                model.cell_init_state: state    # use last state as the initial state for this run\n",
    "            }\n",
    "\n",
    "        _, cost, state, pred = sess.run(\n",
    "            [model.train_op, model.cost, model.cell_final_state, model.pred],\n",
    "            feed_dict=feed_dict)\n",
    "\n",
    "        # plotting\n",
    "        # plt.plot(xs[0, :], res[0].flatten(), 'r', xs[0, :], pred.flatten()[:TIME_STEPS], 'b--')\n",
    "        # plt.ylim((-1.2, 1.2))\n",
    "        # plt.draw()\n",
    "        # plt.pause(0.3)\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            print('cost: ', round(cost, 4))\n",
    "            result = sess.run(merged, feed_dict)\n",
    "            writer.add_summary(result, i)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
