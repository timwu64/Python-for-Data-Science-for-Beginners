{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: java version \"1.8.0_102\"; Java(TM) SE Runtime Environment (build 1.8.0_102-b14); Java HotSpot(TM) 64-Bit Server VM (build 25.102-b14, mixed mode)\n",
      "  Starting server from /Users/tim.wu/anaconda3/lib/python3.6/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /var/folders/61/sfyb5b517dd3tj1_cdjsx6_w0000gn/T/tmp56enfyvw\n",
      "  JVM stdout: /var/folders/61/sfyb5b517dd3tj1_cdjsx6_w0000gn/T/tmp56enfyvw/h2o_tim_wu_started_from_python.out\n",
      "  JVM stderr: /var/folders/61/sfyb5b517dd3tj1_cdjsx6_w0000gn/T/tmp56enfyvw/h2o_tim_wu_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>America/Los_Angeles</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.22.0.3</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>5 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_tim_wu_hnpm9o</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>3.556 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.2 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------\n",
       "H2O cluster uptime:         02 secs\n",
       "H2O cluster timezone:       America/Los_Angeles\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.22.0.3\n",
       "H2O cluster version age:    5 days\n",
       "H2O cluster name:           H2O_from_python_tim_wu_hnpm9o\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    3.556 Gb\n",
       "H2O cluster total cores:    8\n",
       "H2O cluster allowed cores:  8\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.2 final\n",
       "--------------------------  ----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "1431,189,175\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "CPU times: user 270 ms, sys: 165 ms, total: 436 ms\n",
      "Wall time: 32.9 s\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "CPU times: user 286 ms, sys: 153 ms, total: 439 ms\n",
      "Wall time: 57.5 s\n",
      " baseline_model: 0.0656 -> tuned_model: 0.0043\n",
      " baseline_model: 0.0160 -> tuned_model: 0.0005\n",
      " baseline_model: 0.6607 -> tuned_model: 0.3266\n",
      " baseline_model: 0.1545 -> tuned_model: 0.0774\n",
      "H2O session _sid_859a closed.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[381]:\n",
    "\n",
    "\n",
    "import h2o\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "\n",
    "# In[382]:\n",
    "\n",
    "\n",
    "#Step 1\n",
    "\n",
    "h2o.init()\n",
    "\n",
    "\n",
    "# In[383]:\n",
    "\n",
    "\n",
    "data = h2o.import_file(\"http://coursera.h2o.ai/cacao.882.csv\") # importing the cacao dataset\n",
    "\n",
    "\n",
    "# In[384]:\n",
    "\n",
    "\n",
    "data.head(5) # print the first five of our dataset\n",
    "\n",
    "\n",
    "# In[385]:\n",
    "\n",
    "\n",
    "train, valid, test = data.split_frame([0.8,0.1], seed=134) # splitting data to train, test and validation set and setting seed\n",
    "\n",
    "\n",
    "# In[386]:\n",
    "\n",
    "\n",
    "print(\"%d,%d,%d\" % (train.nrows, valid.nrows, test.nrows)) # printing the size of each set\n",
    "\n",
    "\n",
    "# In[387]:\n",
    "\n",
    "\n",
    "# Step 2\n",
    "y = \"Maker Location\" # setting our response variable Y\n",
    "ignoreFields = [ \"REF\" ]\n",
    "xAll = [i for i in train.names if i not in ignoreFields] # setting our independant variables X\n",
    "\n",
    "\n",
    "# In[388]:\n",
    "\n",
    "\n",
    "from h2o.estimators.deeplearning import H2ODeepLearningEstimator\n",
    "\n",
    "\n",
    "# In[389]:\n",
    "\n",
    "\n",
    "# Step 3\n",
    "base_model = H2ODeepLearningEstimator(seed = 134, reproducible = True) # creating a baseline deep learning model with default parameters\n",
    "get_ipython().run_line_magic('time', 'base_model.train(xAll, y, train, validation_frame = valid)')\n",
    "#CPU times: user 280 ms, sys: 60.1 ms, total: 340 ms\n",
    "#Wall time: 23.7 s\n",
    "\n",
    "\n",
    "# In[390]:\n",
    "\n",
    "\n",
    "base_model # performance on training set\n",
    "\n",
    "\n",
    "# In[391]:\n",
    "\n",
    "\n",
    "base_model.model_performance(test) # performance on test set\n",
    "\n",
    "\n",
    "# In[392]:\n",
    "\n",
    "\n",
    "#base_model.plot() # uncomment to see the plot for the scoring history in training and validation set of base model\n",
    "\n",
    "\n",
    "# In[393]:\n",
    "\n",
    "\n",
    "# after seeing the variable importances, some variables decided to be excluded in order to increase the model performance\n",
    "ignoreFields2 = [ \"REF\" , \"Bean Type\", \"Review Date\", \"Origin\"]\n",
    "x2 = [i for i in train.names if i not in ignoreFields2]\n",
    "\n",
    "\n",
    "# In[394]:\n",
    "\n",
    "\n",
    "# Step 4\n",
    "tuned_model = H2ODeepLearningEstimator(epochs = 50,\n",
    "                                      stopping_rounds = 4,\n",
    "                                      stopping_tolerance = 0,\n",
    "                                      stopping_metric = \"logloss\",\n",
    "                                      seed = 134,\n",
    "                                      reproducible = True\n",
    "                                      #hidden = [400,400]\n",
    "                                      )\n",
    "\n",
    "get_ipython().run_line_magic('time', 'tuned_model.train(x2, y, train, validation_frame = valid)')\n",
    "#CPU times: user 213 ms, sys: 44.6 ms, total: 257 ms\n",
    "#Wall time: 38.7 s\n",
    "\n",
    "\n",
    "# In[395]:\n",
    "\n",
    "\n",
    "#tuned_model.plot() # uncomment to see the plot for the scoring history in training and validation set of tuned model\n",
    "\n",
    "\n",
    "# In[396]:\n",
    "\n",
    "\n",
    "tuned_model # tuned model performance on training set\n",
    "\n",
    "\n",
    "# In[397]:\n",
    "\n",
    "\n",
    "tuned_model.model_performance(test) # tuned model performance on test set\n",
    "\n",
    "\n",
    "# In[398]:\n",
    "\n",
    "\n",
    "both_models = [base_model, tuned_model]\n",
    "\n",
    "loglosses = list(map(lambda x: x.logloss(), both_models))\n",
    "print(\" baseline_model: %.4f -> tuned_model: %.4f\" % (loglosses[0],loglosses[1]))\n",
    "\n",
    "mse = list(map(lambda x: x.mse(), both_models))\n",
    "print(\" baseline_model: %.4f -> tuned_model: %.4f\" % (mse[0],mse[1]))\n",
    "\n",
    "# we can see that both logloss and mse had a significant decrease on the tuned model\n",
    "#baseline_model: 0.0656 -> tuned_model: 0.0043\n",
    "#baseline_model: 0.0160 -> tuned_model: 0.0005\n",
    "\n",
    "\n",
    "# In[399]:\n",
    "\n",
    "\n",
    "test1_perf = base_model.model_performance(test) \n",
    "test2_perf = tuned_model.model_performance(test)\n",
    "\n",
    "print(\" baseline_model: %.4f -> tuned_model: %.4f\" % (test1_perf.logloss(),test2_perf.logloss()))\n",
    "print(\" baseline_model: %.4f -> tuned_model: %.4f\" % (test1_perf.mse(),test2_perf.mse()))\n",
    "\n",
    "# logloss and mse had also a significant decrease from base model to tuned model on test set\n",
    "#baseline_model: 0.6603 -> tuned_model: 0.3266\n",
    "#baseline_model: 0.1544 -> tuned_model: 0.0774\n",
    "\n",
    "\n",
    "# In[400]:\n",
    "\n",
    "\n",
    "# Step 5: save the models\n",
    "#model1_path = h2o.save_model(model=base_model, path=\"/Users/mike/Downloads/mymodel1\", force=True)\n",
    "#model2_path = h2o.save_model(model=tuned_model, path=\"/Users/mike/Downloads/mymodel2\", force=True)\n",
    "\n",
    "\n",
    "# In[401]:\n",
    "\n",
    "\n",
    "# Step 6\n",
    "h2o.cluster().shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
